# epipolar geometry

多视图几何。将会看到极点(epipole)，纵向线条(epipolar lines),极线约束(epipolar constraint)。

## 基本概念
我们用针孔相机拍照，将会失去重要信息。比如，图片深度，或是图片点离相机的距离(由于3D-2D转换)。很重要问题，我们能够通过相机得到图片的深度信息。**这个问题答案是用多个相机**。我们眼睛类似相机，使用两个相机称为立体视图。看下OpenCV这方面提供哪些信息。
`Learning OpenCV by Gary Bradsky`有很多这些信息提供。

当获得图像深度之前，我们来理解多视图几何的概念。将会讨论极线几何。下图，展现两个相机拍同一场景视图。

<image src="image/03-01.jpg"/>

如果我们使用左边一个相机，不能找到图中对应的x点，因为在OX投影对图片平面是同一个点。但是同时考虑右边，现在不同点在OX投影相对于右平面的不同点x'。所以有这两个图片，我们能够三角化正确的3D点。这是整个思路。

从右平面中l'投影到不同在OX投影点。我们对应于点x称为极线(epiline)。意味着我们能够在右视图找到x点，沿着极线方向。它应该在线上的某个地方。(这样想，找图像上的点，不需要搜索整个图片，只要沿着极线方向即可。将会提供更好的效果和精度)。称为**极线约束**。相似所有点有相对在另一个图有它相对应的极线。整个XO‘O平面称为极线面。(epipolar plane)

其中O和O’是相机中心。从上面设置提出，你能从右相加O'在左图片上的点如，e。这个被称为极点。极点是过相机中心点的线和图片平面的交叉点。相似e'是左边相机的极点。有些时候极点不一定在图片上，有可能在图片外（意味着，一个相机不能看到另一个相机的点）

所有极线，过极点。所以找到极线，我们能够找到极点。

这个时候，我们来找极线和极点。但是找到他们，我们需要两个多成分，Fundamental Matrix(F)和Essential Matrix(E).E包含旋转和平移信息，描述第一个相对于第二个相机的全局坐标的位置。下图给出:

<image src="image/03-02.jpg"/>
但是我们想用在像素坐标中完成的，对吧？F包含和E同样信息，还提供了两个相机内部信息，为了将两个相机在像素坐标中关联。(如果我们使用修正好的图片和通过聚焦成都划分好的标准化点，F=E)。简单来说，F映射图片点到另一个图片的线。这个从两个匹配的点进行计算。找到F至少需要8个点。越多越好。RANSAC获得更好的鲁棒性效果。